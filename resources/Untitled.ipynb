{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "extreme-peoples",
   "metadata": {},
   "source": [
    "\\section*{Algorithms}\n",
    "\n",
    "\\subsection*{Stochastic Gradient Descent PageRank (SGD PageRank)}\n",
    "\n",
    "\\subsubsection*{Initialization}\n",
    "\\begin{itemize}\n",
    "    \\item The graph's adjacency matrix is represented as \\( M \\).\n",
    "    \\item Initialize the PageRank vector \\( \\mathbf{v} \\) with random values and normalize to have a unit \\( L_1 \\) norm if no initial vector is provided.\n",
    "    \\item Initialize a vector \\( \\mathbf{last\\_v} \\) with infinity to check for convergence.\n",
    "    \\item Set a counter for the number of times each node is visited, \\( \\mathbf{visited\\_counts} \\), to zero.\n",
    "    \\item Define the damping factor \\( d \\), typically set to 0.85.\n",
    "    \\item Set the convergence tolerance, typically \\( 10^{-6} \\).\n",
    "    \\item Define the initial learning rate, which will decay over iterations.\n",
    "\\end{itemize}\n",
    "\n",
    "\\subsubsection*{Iterative Update}\n",
    "For each iteration \\( i \\) up to a maximum number of iterations:\n",
    "\\begin{enumerate}\n",
    "    \\item Calculate the decaying learning rate:\n",
    "    \\begin{equation}\n",
    "        \\alpha_i = \\frac{\\text{initial\\_learning\\_rate}}{1 + (\\frac{i}{10})}.\n",
    "    \\end{equation}\n",
    "    \\item Select a mini-batch of node indices based on the sampling method.\n",
    "    \\item For probability-based sampling, update the probabilities inversely proportional to the visit counts and normalize.\n",
    "    \\item Update the PageRank vector for the selected mini-batch:\n",
    "    \\begin{equation}\n",
    "        \\mathbf{v}_{\\text{mini\\_batch}} = d \\cdot (\\alpha_i \\cdot M_{\\text{mini\\_batch}} \\cdot \\mathbf{v}) + \\left(\\frac{1 - d}{N}\\right).\n",
    "    \\end{equation}\n",
    "    \\item Compute the \\( L_2 \\) norm of the difference between the current and last PageRank values for the mini-batch and store in \\( l2\\_dic \\).\n",
    "    \\item If the \\( L_2 \\) norm is below the tolerance, convergence is achieved.\n",
    "    \\item Check for early stopping criteria based on plateau detection in the \\( L_2 \\) norm changes.\n",
    "\\end{enumerate}\n",
    "\n",
    "\\subsubsection*{Convergence Checking}\n",
    "\\begin{itemize}\n",
    "    \\item After each iteration, check if the \\( L_2 \\) norm of the difference between the updated and previous PageRank vectors is less than the tolerance.\n",
    "    \\item Implement an early stopping mechanism if the change in the \\( L_2 \\) norm is within a small variance over a certain number of iterations.\n",
    "\\end{itemize}\n",
    "\n",
    "\\subsubsection*{Full-Batch Updates}\n",
    "After the iterative updates:\n",
    "\\begin{enumerate}\n",
    "    \\item Perform a defined number of full-batch updates to fine-tune the PageRank values:\n",
    "    \\begin{equation}\n",
    "        \\mathbf{v} = d \\cdot (M \\cdot \\mathbf{v}) + \\left(\\frac{1 - d}{N}\\right).\n",
    "    \\end{equation}\n",
    "\\end{enumerate}\n",
    "\n",
    "\\subsubsection*{Post-Processing}\n",
    "\\begin{enumerate}\n",
    "    \\item Apply a softmax transformation to the PageRank vector to convert the scores into a probability distribution:\n",
    "    \\begin{equation}\n",
    "        P(\\mathbf{v}) = \\frac{e^{\\mathbf{v}}}{\\sum_{j=1}^{N} e^{\\mathbf{v}_j}}.\n",
    "    \\end{equation}\n",
    "    \\item Sample node indices based on the softmax-transformed scores:\n",
    "    \\begin{enumerate}\n",
    "        \\item Perform a fixed number of samplings (e.g., 100 times) using the transformed scores.\n",
    "        \\item Calculate the observed sampling probabilities.\n",
    "        \\item Sample nodes based on the observed probabilities to determine the most influential nodes in the graph.\n",
    "    \\end{enumerate}\n",
    "\\end{enumerate}\n",
    "\n",
    "\\subsection*{Laplacian-Based Scaling Factor \\( S_i \\)}\n",
    "Prior to the SGD PageRank algorithm, calculate the scaling factor for each node:\n",
    "\\begin{equation}\n",
    "    S_i = \\frac{1}{\\text{degree}(i)} + C(D_i),\n",
    "\\end{equation}\n",
    "where \\( C(D_i) \\) is a correction term based on the node's neighborhood.\n",
    "\n",
    "\\subsection*{Dynamic Neighborhood Hopping}\n",
    "To capture extended topological features, perform dynamic neighborhood hopping by raising the adjacency matrix to the power of the defined number of hops \\( \\alpha \\):\n",
    "\\begin{equation}\n",
    "    A^{(\\alpha)} = A^{\\alpha\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scentinel",
   "language": "python",
   "name": "scentinel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
